{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimension: Geography (Dim_Geo)\n",
    "'''\n",
    "This block extracts and validates geographic attributes used for analytical joins.\n",
    "\n",
    "Purpose:\n",
    "- Build a clean Geography dimension\n",
    "- Preserve special characters (e.g., Eastern European states)\n",
    "- Assign stable surrogate keys\n",
    "\n",
    "Notes:\n",
    "- Encoding is critical for this dataset\n",
    "- Validation is performed inline before saving\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# FILE SETUP\n",
    "# ------------------------------------------------------------------------------\n",
    "file_path = r\"D:\\Data Lake\\Bronze\\DataCo_Final_2M.csv\"\n",
    "folder_path = r\"D:\\Data Lake\\testing\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. LOAD DATA WITH SAFE ENCODING\n",
    "# ------------------------------------------------------------------------------\n",
    "# cp1252 preserves Eastern European characters better than latin-1\n",
    "try:\n",
    "    print(\"Attempting to read with cp1252 encoding...\")\n",
    "    df_main = pl.read_csv(file_path, encoding=\"cp1252\")\n",
    "except Exception as e:\n",
    "    print(f\"cp1252 failed ({e}). Falling back to utf-8.\")\n",
    "    df_main = pl.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. EXTRACT GEOGRAPHIC ATTRIBUTES\n",
    "# ------------------------------------------------------------------------------\n",
    "dim_geo = (\n",
    "    df_main\n",
    "    .select([\"order_state\", \"order_country\", \"order_region\", \"market\"])\n",
    "    .unique()\n",
    "    .sort([\"order_state\", \"order_country\"])\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. VALIDATION CHECK (ENCODING SANITY)\n",
    "# ------------------------------------------------------------------------------\n",
    "# Verify that special characters survived encoding\n",
    "check = dim_geo.filter(pl.col(\"order_state\").str.contains(\"ilina\"))\n",
    "\n",
    "print(\"\\nGeography encoding validation:\")\n",
    "if check.height > 0:\n",
    "    print(\"Special characters preserved correctly:\")\n",
    "    print(check.head())\n",
    "else:\n",
    "    print(\"Warning: expected values not found. Verify source file.\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. ASSIGN SURROGATE KEYS\n",
    "# ------------------------------------------------------------------------------\n",
    "dim_geo = dim_geo.with_row_index(name=\"geo_id\", offset=1000)\n",
    "dim_geo = dim_geo.select(\n",
    "    [\"geo_id\", \"order_state\", \"order_country\", \"order_region\", \"market\"]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. EXPORT DIMENSION TABLE\n",
    "# ------------------------------------------------------------------------------\n",
    "output_filename = \"dim_geo.parquet\"\n",
    "output_path = os.path.join(folder_path, output_filename)\n",
    "\n",
    "print(f\"Saving Geography dimension to: {output_path}\")\n",
    "dim_geo.write_parquet(output_path)\n",
    "\n",
    "print(\"Geography dimension creation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eeba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimension: Customer Geography (Dim_Customer_Geo)\n",
    "'''\n",
    "This block creates the Customer Geography dimension table used for analytical joins.\n",
    "\n",
    "Purpose:\n",
    "- Extract unique customer location combinations\n",
    "- Standardize column naming\n",
    "- Assign stable surrogate keys\n",
    "\n",
    "Notes:\n",
    "- This is a one-time setup step\n",
    "- Dimension keys should not be regenerated after initial load\n",
    "- Output is consumed by the Silver → SQL pipeline\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# FILE SETUP\n",
    "# ------------------------------------------------------------------------------\n",
    "# Adjust input path if required\n",
    "input_csv = r\"D:\\Data Lake\\Bronze\\DataCo_Final_2M.csv\"\n",
    "output_parquet = \"Dim_Customer_Geo.parquet\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. LOAD CLEAN SOURCE DATA\n",
    "# ------------------------------------------------------------------------------\n",
    "# Default encoding is sufficient here as the source file is already normalized\n",
    "df_raw = pl.read_csv(input_csv)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. STANDARDIZE COLUMN NAMES\n",
    "# ------------------------------------------------------------------------------\n",
    "# Enforce snake_case for schema consistency\n",
    "df_raw.columns = [\n",
    "    c.strip()\n",
    "     .lower()\n",
    "     .replace(\" \", \"_\")\n",
    "     .replace(\"(\", \"_\")\n",
    "     .replace(\")\", \"_\")\n",
    "    for c in df_raw.columns\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. BUILD CUSTOMER GEOGRAPHY DIMENSION\n",
    "# ------------------------------------------------------------------------------\n",
    "target_cols = [\"customer_state\", \"customer_country\"]\n",
    "\n",
    "dim_cust_geo = (\n",
    "    df_raw\n",
    "    .select(target_cols)\n",
    "    .unique()\n",
    "    .sort(target_cols)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. ASSIGN SURROGATE KEYS\n",
    "# ------------------------------------------------------------------------------\n",
    "dim_cust_geo = dim_cust_geo.with_row_index(\n",
    "    name=\"customer_geo_id\",\n",
    "    offset=100\n",
    ")\n",
    "\n",
    "dim_cust_geo = dim_cust_geo.select(\n",
    "    [\"customer_geo_id\"] + target_cols\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. EXPORT DIMENSION TABLE\n",
    "# ------------------------------------------------------------------------------\n",
    "print(f\"Generated {dim_cust_geo.height} unique customer locations.\")\n",
    "print(dim_cust_geo.head())\n",
    "\n",
    "dim_cust_geo.write_parquet(output_parquet)\n",
    "print(f\"Saved Customer Geography dimension to: {output_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dimension: Product (Dim_Product)\n",
    "'''\n",
    "This block creates the Product dimension table used for analytical joins.\n",
    "\n",
    "Purpose:\n",
    "- Extract unique product definitions\n",
    "- Preserve product → category → department hierarchy\n",
    "- Assign stable surrogate keys for fact table joins\n",
    "\n",
    "Notes:\n",
    "- This is a one-time setup step\n",
    "- Product keys should remain stable once created\n",
    "- Output is consumed by the Silver → SQL pipeline\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# FILE SETUP\n",
    "# ------------------------------------------------------------------------------\n",
    "input_csv = r\"D:\\Data Lake\\Bronze\\DataCo_Final_2M.csv\"\n",
    "output_parquet = \"Dim_Product.parquet\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. LOAD CLEAN SOURCE DATA\n",
    "# ------------------------------------------------------------------------------\n",
    "# Default encoding is sufficient as the source file has already been normalized\n",
    "df_raw = pl.read_csv(input_csv)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. STANDARDIZE COLUMN NAMES\n",
    "# ------------------------------------------------------------------------------\n",
    "# Enforce snake_case for consistency across all dimensions\n",
    "df_raw.columns = [\n",
    "    c.strip()\n",
    "     .lower()\n",
    "     .replace(\" \", \"_\")\n",
    "     .replace(\"(\", \"_\")\n",
    "     .replace(\")\", \"_\")\n",
    "    for c in df_raw.columns\n",
    "]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. BUILD PRODUCT DIMENSION\n",
    "# ------------------------------------------------------------------------------\n",
    "# Product uniqueness is defined by name + category + department\n",
    "target_cols = [\"product_name\", \"category_name\", \"department_name\"]\n",
    "\n",
    "dim_product = (\n",
    "    df_raw\n",
    "    .select(target_cols)\n",
    "    .unique()\n",
    "    .sort(target_cols)\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. ASSIGN SURROGATE KEYS\n",
    "# ------------------------------------------------------------------------------\n",
    "dim_product = dim_product.with_row_index(\n",
    "    name=\"product_key\",\n",
    "    offset=100\n",
    ")\n",
    "\n",
    "dim_product = dim_product.select(\n",
    "    [\"product_key\"] + target_cols\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. EXPORT DIMENSION TABLE\n",
    "# ------------------------------------------------------------------------------\n",
    "print(f\"Generated {dim_product.height} unique products.\")\n",
    "print(dim_product.head())\n",
    "\n",
    "dim_product.write_parquet(output_parquet)\n",
    "print(f\"Saved Product dimension to: {output_parquet}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
